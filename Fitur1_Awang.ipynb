{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tensorflow as tf\n",
    "import zipfile,os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir= \"fitur 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=20,  # Rotasi gambar dalam rentang 20 derajat\n",
    "                    width_shift_range=0.2,  # Pergeseran horizontal gambar sebesar 20% dari lebar gambar\n",
    "                    height_shift_range=0.2,  # Pergeseran vertikal gambar sebesar 20% dari tinggi gambar\n",
    "                    shear_range=0.2,  # Shearing gambar dengan rentang 20 derajat\n",
    "                    zoom_range=0.2,  # Perbesaran dan pengecilan gambar sebesar 20%\n",
    "                    horizontal_flip=True,  # Flipping gambar secara horizontal\n",
    "                    fill_mode='nearest' ,# Mengisi pixel yang kosong dengan pixel terdekat  \n",
    "                    validation_split = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 images belonging to 8 classes.\n",
      "Found 480 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        dir,  # direktori data latih\n",
    "        target_size=(100, 150),  # mengubah resolusi seluruh gambar menjadi 100x150 piksel\n",
    "        shuffle =True,\n",
    "        class_mode='categorical',\n",
    "        subset= 'training'\n",
    "        )\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        dir, # direktori data validasi\n",
    "        target_size=(100, 150), # mengubah resolusi seluruh gambar menjadi 100x150 piksel\n",
    "        class_mode='categorical',\n",
    "        subset= 'validation'\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the generators with RepeatDataset\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, *(100, 150, 3)], [None, 8])\n",
    ").repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: validation_generator,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, *(100, 150, 3)], [None, 8])\n",
    ").repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(100, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(8, activation='softmax') \n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy')>0.7):\n",
    "      print(\"\\nAkurasi telah mencapai >70%!\")\n",
    "      self.model.stop_training = True\n",
    "callbacks = myCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.3203 - accuracy: 0.8871 - val_loss: 1.8464 - val_accuracy: 0.6380\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 23s 1s/step - loss: 0.2124 - accuracy: 0.9121 - val_loss: 1.7482 - val_accuracy: 0.6302\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 32s 2s/step - loss: 0.2552 - accuracy: 0.9023 - val_loss: 1.5995 - val_accuracy: 0.6380\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 31s 2s/step - loss: 0.2684 - accuracy: 0.9254 - val_loss: 1.8285 - val_accuracy: 0.6224\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 31s 2s/step - loss: 0.2057 - accuracy: 0.9194 - val_loss: 1.6652 - val_accuracy: 0.6484\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 24s 1s/step - loss: 0.1879 - accuracy: 0.9375 - val_loss: 1.7625 - val_accuracy: 0.6354\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.1904 - accuracy: 0.9375 - val_loss: 1.7805 - val_accuracy: 0.6120\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.1417 - accuracy: 0.9453 - val_loss: 1.9857 - val_accuracy: 0.6276\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2255 - accuracy: 0.9277 - val_loss: 2.0032 - val_accuracy: 0.6120\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.2144 - accuracy: 0.9214 - val_loss: 1.9006 - val_accuracy: 0.6380\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.2269 - accuracy: 0.9093 - val_loss: 1.8259 - val_accuracy: 0.6406\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 32s 2s/step - loss: 0.1721 - accuracy: 0.9395 - val_loss: 1.6138 - val_accuracy: 0.6406\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 29s 2s/step - loss: 0.2176 - accuracy: 0.9173 - val_loss: 1.7544 - val_accuracy: 0.6198\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 32s 2s/step - loss: 0.1639 - accuracy: 0.9516 - val_loss: 1.8383 - val_accuracy: 0.6484\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 32s 2s/step - loss: 0.1653 - accuracy: 0.9315 - val_loss: 1.9773 - val_accuracy: 0.6224\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 31s 2s/step - loss: 0.2433 - accuracy: 0.9254 - val_loss: 2.0201 - val_accuracy: 0.6250\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 32s 2s/step - loss: 0.2342 - accuracy: 0.9153 - val_loss: 2.0892 - val_accuracy: 0.6328\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 32s 2s/step - loss: 0.2074 - accuracy: 0.9355 - val_loss: 1.8726 - val_accuracy: 0.6406\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 33s 2s/step - loss: 0.1647 - accuracy: 0.9473 - val_loss: 1.9533 - val_accuracy: 0.6068\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 0.1556 - accuracy: 0.9395 - val_loss: 1.7967 - val_accuracy: 0.6510\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 14s 892ms/step - loss: 0.2086 - accuracy: 0.9234 - val_loss: 1.7198 - val_accuracy: 0.6250\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 24s 2s/step - loss: 0.2123 - accuracy: 0.9194 - val_loss: 1.8338 - val_accuracy: 0.6380\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 17s 1s/step - loss: 0.1862 - accuracy: 0.9355 - val_loss: 1.6553 - val_accuracy: 0.6458\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 11s 731ms/step - loss: 0.1479 - accuracy: 0.9435 - val_loss: 1.7042 - val_accuracy: 0.6536\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 13s 842ms/step - loss: 0.1912 - accuracy: 0.9254 - val_loss: 1.5463 - val_accuracy: 0.6823\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 12s 777ms/step - loss: 0.2012 - accuracy: 0.9395 - val_loss: 2.0382 - val_accuracy: 0.6172\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 13s 806ms/step - loss: 0.2145 - accuracy: 0.9294 - val_loss: 1.8010 - val_accuracy: 0.6328\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 13s 801ms/step - loss: 0.1850 - accuracy: 0.9375 - val_loss: 1.6392 - val_accuracy: 0.6536\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 12s 772ms/step - loss: 0.1326 - accuracy: 0.9577 - val_loss: 1.5878 - val_accuracy: 0.6536\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 14s 887ms/step - loss: 0.2545 - accuracy: 0.9274 - val_loss: 1.8125 - val_accuracy: 0.6042\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.2992 - accuracy: 0.9032 - val_loss: 1.5063 - val_accuracy: 0.6406\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 16s 991ms/step - loss: 0.2190 - accuracy: 0.9214 - val_loss: 1.8074 - val_accuracy: 0.6302\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 15s 944ms/step - loss: 0.1287 - accuracy: 0.9597 - val_loss: 1.6004 - val_accuracy: 0.6615\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 13s 835ms/step - loss: 0.1910 - accuracy: 0.9375 - val_loss: 1.7572 - val_accuracy: 0.6589\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 14s 885ms/step - loss: 0.2070 - accuracy: 0.9194 - val_loss: 1.8947 - val_accuracy: 0.6172\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 16s 994ms/step - loss: 0.1745 - accuracy: 0.9395 - val_loss: 1.7449 - val_accuracy: 0.6641\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 15s 957ms/step - loss: 0.2361 - accuracy: 0.9173 - val_loss: 2.0973 - val_accuracy: 0.5859\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.2541 - accuracy: 0.9219 - val_loss: 1.8272 - val_accuracy: 0.6198\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 28s 2s/step - loss: 0.1741 - accuracy: 0.9375 - val_loss: 1.6674 - val_accuracy: 0.6250\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 27s 2s/step - loss: 0.1183 - accuracy: 0.9617 - val_loss: 1.8294 - val_accuracy: 0.6458\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 27s 2s/step - loss: 0.1381 - accuracy: 0.9476 - val_loss: 1.6193 - val_accuracy: 0.6562\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 31s 2s/step - loss: 0.2817 - accuracy: 0.9133 - val_loss: 1.6413 - val_accuracy: 0.6745\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.1587 - accuracy: 0.9476 - val_loss: 1.5986 - val_accuracy: 0.6198\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 16s 1s/step - loss: 0.1701 - accuracy: 0.9476 - val_loss: 1.8197 - val_accuracy: 0.6068\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.1404 - accuracy: 0.9577 - val_loss: 1.8521 - val_accuracy: 0.6146\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 19s 1s/step - loss: 0.1927 - accuracy: 0.9316 - val_loss: 1.7306 - val_accuracy: 0.6458\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 33s 2s/step - loss: 0.1924 - accuracy: 0.9375 - val_loss: 1.8345 - val_accuracy: 0.6302\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 22s 1s/step - loss: 0.1353 - accuracy: 0.9617 - val_loss: 1.6294 - val_accuracy: 0.6484\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 20s 1s/step - loss: 0.1269 - accuracy: 0.9590 - val_loss: 1.9700 - val_accuracy: 0.6432\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 18s 1s/step - loss: 0.1475 - accuracy: 0.9516 - val_loss: 1.5372 - val_accuracy: 0.6615\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch= 16,  \n",
    "    epochs= 50,  \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps= 12,  \n",
    "    verbose=1,  \n",
    "    batch_size= 16,  \n",
    "    callbacks=[callbacks]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
